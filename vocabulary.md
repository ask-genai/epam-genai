# Generative AI Vocabulary (Glossary)

This document contains key terms and concepts essential for understanding Generative AI applications in software development.

## Core Concepts

### 1. Large Language Model (LLM)
A neural network trained on vast amounts of text data to predict and generate human-like text. LLMs understand context and can perform various language tasks including translation, summarization, and question-answering. Examples: GPT-4, Claude, LLaMA.

### 2. Prompt Engineering
The art of crafting effective input instructions to AI models to elicit desired outputs. It involves understanding how to structure queries, provide context, and use specific language patterns that the model responds well to.

### 3. Hallucination
When an AI model generates plausible-sounding but false or fabricated information. This is a significant challenge in chatbots and content generation systems where accuracy is critical.

### 4. Fine-tuning
The process of adapting a pre-trained AI model to specific tasks or domains by training it further on task-specific data. This improves performance on specialized applications.

### 5. Token
A unit of text (word, subword, or character) that an AI model processes. Token limits affect how much text a model can handle at once, impacting performance and cost.

### 6. Embeddings
Vector representations of text that capture semantic meaning. AI models use embeddings to understand relationships between words and concepts, enabling similarity matching and semantic search.

### 7. Context Window
The maximum amount of text (in tokens) that an AI model can consider at once. Longer context windows allow models to handle more complex, multi-part conversations.

## Technical Terms

### 8. Neural Network
A computing system inspired by biological neural networks. It consists of interconnected nodes (neurons) that learn patterns from data through adjustment of weights and biases.

### 9. Transformer Architecture
The neural network architecture underlying most modern LLMs. It uses attention mechanisms to process all parts of input data in parallel, improving efficiency and understanding of long-range dependencies.

### 10. Attention Mechanism
A technique allowing models to focus on relevant parts of input when generating output. This is critical for understanding context and maintaining coherence in generated text.

### 11. Pre-training
The initial training phase where AI models learn from large, diverse datasets before being adapted to specific tasks. This builds foundational knowledge and language understanding.

### 12. RLHF (Reinforcement Learning from Human Feedback)
A technique used to align AI model outputs with human preferences. Human raters evaluate model responses, and this feedback trains reward models that guide the AI's behavior.

## Business and Implementation Terms

### 13. API (Application Programming Interface)
A set of rules allowing different software applications to communicate. Most AI services are accessed through APIs, enabling integration into existing systems.

### 14. Inference
The process of running a trained AI model on new data to generate predictions or outputs. In production, inference happens when users interact with the AI system.

### 15. Model Bias
Systematic prejudices in AI model outputs resulting from biases in training data or model design. This can lead to unfair or discriminatory outputs affecting certain user groups.

### 16. Latency
The time delay between when a user sends a request to an AI system and when they receive a response. Critical for user experience in real-time applications like chatbots.

### 17. Scalability
The ability of an AI system to handle increasing amounts of work (users, requests, data) while maintaining acceptable performance. Important for enterprise deployments.

## Application-Specific Terms

### 18. Chatbot
An AI program designed to simulate conversation with users. Can range from simple rule-based bots to sophisticated LLM-powered systems that understand context and intent.

### 19. Natural Language Processing (NLP)
A subfield of AI focused on enabling computers to understand, interpret, and generate human language. Foundation for chatbots, translation, and text analysis.

### 20. Intent Recognition
The task of identifying what the user wants to accomplish in their message. Critical for chatbots to route conversations correctly and provide relevant responses.

### 21. Entity Recognition
Identifying and extracting specific information types (names, dates, locations) from text. Used in chatbots for understanding user requests and extracting relevant data.

### 22. Sentiment Analysis
Determining the emotional tone (positive, negative, neutral) of text. Useful in customer support chatbots to understand customer satisfaction and emotional state.

### 23. Knowledge Base
A structured collection of information, facts, and procedures used by AI systems. Chatbots use knowledge bases to provide accurate, consistent answers.

### 24. Model Drift
Gradual degradation in AI model performance over time as real-world data changes from training data. Requires periodic model retraining and updating.

### 25. Compliance
Adherence to laws and regulations governing AI use, including data privacy (GDPR, CCPA), bias prevention, and transparency requirements. Essential for business applications.

---

*This vocabulary covers 25 essential terms for Generative AI application development. Additional terms may be added as the course progresses.*
